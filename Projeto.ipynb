{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias para análise e modelagem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from haversine import haversine\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os conjuntos de dados de treino e teste\n",
    "treino_df = pd.read_csv('train.csv')\n",
    "teste_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1458644 entries, 0 to 1458643\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   id                  1458644 non-null  object \n",
      " 1   vendor_id           1458644 non-null  int64  \n",
      " 2   pickup_datetime     1458644 non-null  object \n",
      " 3   dropoff_datetime    1458644 non-null  object \n",
      " 4   passenger_count     1458644 non-null  int64  \n",
      " 5   pickup_longitude    1458644 non-null  float64\n",
      " 6   pickup_latitude     1458644 non-null  float64\n",
      " 7   dropoff_longitude   1458644 non-null  float64\n",
      " 8   dropoff_latitude    1458644 non-null  float64\n",
      " 9   store_and_fwd_flag  1458644 non-null  object \n",
      " 10  trip_duration       1458644 non-null  int64  \n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 122.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Exibir resumo do DataFrame de treino (treino_df)\n",
    "treino_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 625134 entries, 0 to 625133\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  625134 non-null  object \n",
      " 1   vendor_id           625134 non-null  int64  \n",
      " 2   pickup_datetime     625134 non-null  object \n",
      " 3   passenger_count     625134 non-null  int64  \n",
      " 4   pickup_longitude    625134 non-null  float64\n",
      " 5   pickup_latitude     625134 non-null  float64\n",
      " 6   dropoff_longitude   625134 non-null  float64\n",
      " 7   dropoff_latitude    625134 non-null  float64\n",
      " 8   store_and_fwd_flag  625134 non-null  object \n",
      "dtypes: float64(4), int64(2), object(3)\n",
      "memory usage: 42.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Exibir resumo do DataFrame de teste (teste_df)\n",
    "teste_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir uma função para calcular a distância Haversine entre dois pontos geográficos\n",
    "def haversine_distancia(linha):\n",
    "    inicio = (linha['pickup_latitude'], linha['pickup_longitude'])\n",
    "    fim = (linha['dropoff_latitude'], linha['dropoff_longitude'])\n",
    "    return haversine(inicio, fim)\n",
    "\n",
    "# Definir uma função para categorizar a hora do dia\n",
    "def categorizar_hora(hora):\n",
    "    if 0 <= hora < 6:\n",
    "        return 'madrugada'\n",
    "    elif 6 <= hora < 12:\n",
    "        return 'manhã'\n",
    "    elif 12 <= hora < 18:\n",
    "        return 'tarde'\n",
    "    else:\n",
    "        return 'noite'\n",
    "\n",
    "# Função principal para pré-processamento dos dados\n",
    "def pre_processo_dados(df, is_train=True):\n",
    "    # Converter a coluna de data e hora para datetime e extrair características\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "    df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['pickup_weekday'] = df['pickup_datetime'].dt.weekday\n",
    "    df['pickup_month'] = df['pickup_datetime'].dt.month\n",
    "    \n",
    "    # Calcular a distância Haversine para cada viagem\n",
    "    df['distance'] = df.apply(haversine_distancia, axis=1)\n",
    "    \n",
    "    # Criar uma nova feature com base no período do dia\n",
    "    df['periodo_dia'] = df['pickup_hour'].apply(categorizar_hora)\n",
    "    \n",
    "    # Codificar variáveis categóricas em variáveis dummy\n",
    "    df = pd.get_dummies(df, columns=['periodo_dia'], drop_first=True)\n",
    "    \n",
    "    # Definir as colunas que não serão usadas para modelagem e devem ser removidas\n",
    "    colunas = ['id', 'vendor_id', 'store_and_fwd_flag', 'pickup_datetime']\n",
    "    if is_train and 'dropoff_datetime' in df.columns:\n",
    "        colunas.append('dropoff_datetime')\n",
    "    df = df.drop(columns=colunas)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar os dados de treino e teste\n",
    "treino_df = pre_processo_dados(treino_df, is_train=True)\n",
    "teste_df = pre_processo_dados(teste_df, is_train=False)\n",
    "\n",
    "# Definir o número de clusters para K-Means\n",
    "n_clusters = 10\n",
    "\n",
    "# Aplicar K-Means para o pickup\n",
    "kmeans_pickup = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "treino_df['pickup_cluster'] = kmeans_pickup.fit_predict(treino_df[['pickup_latitude', 'pickup_longitude']])\n",
    "teste_df['pickup_cluster'] = kmeans_pickup.predict(teste_df[['pickup_latitude', 'pickup_longitude']])\n",
    "\n",
    "# Aplicar K-Means para o dropoff\n",
    "kmeans_dropoff = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "treino_df['dropoff_cluster'] = kmeans_dropoff.fit_predict(treino_df[['dropoff_latitude', 'dropoff_longitude']])\n",
    "teste_df['dropoff_cluster'] = kmeans_dropoff.predict(teste_df[['dropoff_latitude', 'dropoff_longitude']])\n",
    "\n",
    "# Remover outliers baseados na distância e duração\n",
    "treino_df = treino_df[(treino_df['distance'] > 0) & (treino_df['trip_duration'] > 0)]\n",
    "treino_df = treino_df[treino_df['trip_duration'] < treino_df['trip_duration'].quantile(0.99)]\n",
    "\n",
    "# Transformação logarítmica da variável alvo\n",
    "treino_df['log_trip_duration'] = np.log1p(treino_df['trip_duration'])\n",
    "\n",
    "# Separar as variáveis dependentes e independentes\n",
    "X = treino_df.drop(columns=['trip_duration', 'log_trip_duration'])\n",
    "y = treino_df['log_trip_duration']\n",
    "\n",
    "# Dividir os dados de treino para validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o pipeline para XGBRegressor\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "])\n",
    "\n",
    "# Definir os hiperparâmetros para o Grid Search do XGBRegressor\n",
    "param_grid_xgb = {\n",
    "    'model__n_estimators': [100, 300],\n",
    "    'model__max_depth': [10, 15],\n",
    "    'model__learning_rate': [0.01, 0.1],\n",
    "    'model__subsample': [0.8, 1],\n",
    "    'model__colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Definir o scorer RMSLE para o GridSearchCV\n",
    "rmsle_scorer = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_log_error(y_true, y_pred)), greater_is_better=False)\n",
    "\n",
    "# Configurar o Grid Search para o XGBRegressor usando RMSLE\n",
    "grid_search_xgb = GridSearchCV(pipeline_xgb, param_grid_xgb, cv=3, scoring=rmsle_scorer, n_jobs=-1)\n",
    "\n",
    "# Treinar o modelo XGBRegressor\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Melhor combinação de hiperparâmetros\n",
    "print(f\"Melhores hiperparâmetros para XGBRegressor: {grid_search_xgb.best_params_}\")\n",
    "\n",
    "# Prever no conjunto de validação\n",
    "y_pred_log_xgb = grid_search_xgb.predict(X_val)\n",
    "y_pred_xgb = np.expm1(y_pred_log_xgb)\n",
    "\n",
    "# Reverter a transformação logarítmica de y_val\n",
    "y_val_actual = np.expm1(y_val)\n",
    "\n",
    "# Avaliar o modelo com RMSLE\n",
    "rmsle_xgb = np.sqrt(mean_squared_log_error(y_val_actual, y_pred_xgb))\n",
    "print(f'Root Mean Squared Logarithmic Error para XGBRegressor: {rmsle_xgb}')\n",
    "\n",
    "# Previsões no conjunto de teste\n",
    "teste_df['distance'] = teste_df['distance'].replace(0, teste_df['distance'].mean())  # Evitar divisão por zero\n",
    "test_predictions_log_xgb = grid_search_xgb.predict(teste_df)\n",
    "test_predictions_xgb = np.expm1(test_predictions_log_xgb)\n",
    "\n",
    "# Salvar as previsões\n",
    "output_xgb = pd.DataFrame({'id': teste_df.index, 'predicted_trip_duration': test_predictions_xgb})\n",
    "output_xgb.to_csv('test_predictions_xgboost.csv', index=False)\n",
    "\n",
    "print('Modelo XGBRegressor finalizado com sucesso!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de dispersão das previsões versus valores reais\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val_actual, y_pred_xgb, alpha=0.3)\n",
    "plt.plot([0, max(y_val_actual)], [0, max(y_val_actual)], 'r--', lw=2)  # Linha de identidade\n",
    "plt.xlabel('Valores Reais')\n",
    "plt.ylabel('Previsões')\n",
    "plt.title('Previsões vs. Valores Reais')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras das Distribuições das Previsões de Duração da Viagem\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(test_predictions_xgb, bins=30, kde=True)\n",
    "plt.xlabel('Duração da Viagem Prevista')\n",
    "plt.title('Distribuição das Previsões de Duração da Viagem')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras das Previsões de Duração da Viagem no Conjunto de Teste\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(test_predictions_xgb, bins=30, kde=True)\n",
    "plt.xlabel('Duração da Viagem Prevista')\n",
    "plt.title('Distribuição das Previsões de Duração da Viagem no Conjunto de Teste')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>predicted_trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id3004672</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:58</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.988129</td>\n",
       "      <td>40.732029</td>\n",
       "      <td>-73.990173</td>\n",
       "      <td>40.756680</td>\n",
       "      <td>N</td>\n",
       "      <td>13.545346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id3505355</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:53</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.964203</td>\n",
       "      <td>40.679993</td>\n",
       "      <td>-73.959808</td>\n",
       "      <td>40.655403</td>\n",
       "      <td>N</td>\n",
       "      <td>9.395350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id1217141</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:47</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.997437</td>\n",
       "      <td>40.737583</td>\n",
       "      <td>-73.986160</td>\n",
       "      <td>40.729523</td>\n",
       "      <td>N</td>\n",
       "      <td>6.988141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id2150126</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-30 23:59:41</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.956070</td>\n",
       "      <td>40.771900</td>\n",
       "      <td>-73.986427</td>\n",
       "      <td>40.730469</td>\n",
       "      <td>N</td>\n",
       "      <td>16.986739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id1598245</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:33</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.970215</td>\n",
       "      <td>40.761475</td>\n",
       "      <td>-73.961510</td>\n",
       "      <td>40.755890</td>\n",
       "      <td>N</td>\n",
       "      <td>7.475345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625129</th>\n",
       "      <td>id3008929</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:02:52</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.003464</td>\n",
       "      <td>40.725105</td>\n",
       "      <td>-74.001251</td>\n",
       "      <td>40.733643</td>\n",
       "      <td>N</td>\n",
       "      <td>4.284770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625130</th>\n",
       "      <td>id3700764</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:01:52</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.006363</td>\n",
       "      <td>40.743782</td>\n",
       "      <td>-73.953407</td>\n",
       "      <td>40.782467</td>\n",
       "      <td>N</td>\n",
       "      <td>19.627640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625131</th>\n",
       "      <td>id2568735</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:01:24</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.972267</td>\n",
       "      <td>40.759865</td>\n",
       "      <td>-73.876602</td>\n",
       "      <td>40.748665</td>\n",
       "      <td>N</td>\n",
       "      <td>28.311143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625132</th>\n",
       "      <td>id1384355</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:28</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.976501</td>\n",
       "      <td>40.733562</td>\n",
       "      <td>-73.854263</td>\n",
       "      <td>40.891788</td>\n",
       "      <td>N</td>\n",
       "      <td>32.397213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625133</th>\n",
       "      <td>id0621643</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:22</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.981850</td>\n",
       "      <td>40.716881</td>\n",
       "      <td>-73.969330</td>\n",
       "      <td>40.769379</td>\n",
       "      <td>N</td>\n",
       "      <td>17.951195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625134 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  vendor_id      pickup_datetime  passenger_count  \\\n",
       "0       id3004672          1  2016-06-30 23:59:58                1   \n",
       "1       id3505355          1  2016-06-30 23:59:53                1   \n",
       "2       id1217141          1  2016-06-30 23:59:47                1   \n",
       "3       id2150126          2  2016-06-30 23:59:41                1   \n",
       "4       id1598245          1  2016-06-30 23:59:33                1   \n",
       "...           ...        ...                  ...              ...   \n",
       "625129  id3008929          1  2016-01-01 00:02:52                1   \n",
       "625130  id3700764          1  2016-01-01 00:01:52                1   \n",
       "625131  id2568735          1  2016-01-01 00:01:24                2   \n",
       "625132  id1384355          1  2016-01-01 00:00:28                1   \n",
       "625133  id0621643          2  2016-01-01 00:00:22                2   \n",
       "\n",
       "        pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0             -73.988129        40.732029         -73.990173   \n",
       "1             -73.964203        40.679993         -73.959808   \n",
       "2             -73.997437        40.737583         -73.986160   \n",
       "3             -73.956070        40.771900         -73.986427   \n",
       "4             -73.970215        40.761475         -73.961510   \n",
       "...                  ...              ...                ...   \n",
       "625129        -74.003464        40.725105         -74.001251   \n",
       "625130        -74.006363        40.743782         -73.953407   \n",
       "625131        -73.972267        40.759865         -73.876602   \n",
       "625132        -73.976501        40.733562         -73.854263   \n",
       "625133        -73.981850        40.716881         -73.969330   \n",
       "\n",
       "        dropoff_latitude store_and_fwd_flag  predicted_trip_duration  \n",
       "0              40.756680                  N                13.545346  \n",
       "1              40.655403                  N                 9.395350  \n",
       "2              40.729523                  N                 6.988141  \n",
       "3              40.730469                  N                16.986739  \n",
       "4              40.755890                  N                 7.475345  \n",
       "...                  ...                ...                      ...  \n",
       "625129         40.733643                  N                 4.284770  \n",
       "625130         40.782467                  N                19.627640  \n",
       "625131         40.748665                  N                28.311143  \n",
       "625132         40.891788                  N                32.397213  \n",
       "625133         40.769379                  N                17.951195  \n",
       "\n",
       "[625134 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dicionário de tradução das colunas para português\n",
    "colunas = {\n",
    "    'id': 'identificador',\n",
    "    'vendor_id': 'id_do_vendedor',\n",
    "    'pickup_datetime': 'data_hora_coleta',\n",
    "    'passenger_count': 'numero_passageiros',\n",
    "    'pickup_longitude': 'longitude_coleta',\n",
    "    'pickup_latitude': 'latitude_coleta',\n",
    "    'dropoff_longitude': 'longitude_destino',\n",
    "    'dropoff_latitude': 'latitude_destino',\n",
    "    'store_and_fwd_flag': 'indicador_armazenar_encaminhar',\n",
    "    'predicted_trip_duration': 'duracao_viagem_prevista_(min)'\n",
    "    }\n",
    "\n",
    "# Carregar os datasets de teste e das previsões feitas pelo modelo\n",
    "tabela_teste = pd.read_csv('test.csv')\n",
    "tabela_resultado = pd.read_csv('test_predictions_xgboost.csv')\n",
    "\n",
    "# Converter a duração prevista das viagens de segundos para minutos e arredondar para o inteiro mais próximo\n",
    "tabela_resultado['predicted_trip_duration'] = (tabela_resultado['predicted_trip_duration']/60).round(0)\n",
    "\n",
    "# Combinar o dataset de teste original com as previsões das durações das viagens\n",
    "tabela = pd.concat([tabela_teste, tabela_resultado['predicted_trip_duration']], axis=1)\n",
    "\n",
    "# Renomear as colunas do dataset combinado para português, utilizando o dicionário de tradução\n",
    "tabela = tabela.rename(columns=colunas)\n",
    "\n",
    "# Exibir o dataframe resultante com as colunas traduzidas e as previsões\n",
    "display(tabela)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
